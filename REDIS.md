# 1. 캐시 개념 및 전략

## 1.1 캐시(Cache)란?

캐시는 데이터나 연산 결과를 **미리 저장**하여 동일한 요청이 있을 때 빠르게 응답할 수 있도록 하는 임시 저장소입니다.

주요 목적은 **응답 속도 향상**, **데이터베이스 부하 감소**, **네트워크 비용 절감**, **시스템 확장성 향상**, 그리고 **사용자 경험 개선**에 있습니다.

### 1.1.1 캐시의 주요 목적

- **응답 속도 향상**: 반복되는 요청에 대해 미리 저장된 데이터를 즉시 반환
- **데이터베이스 부하 감소**: 자주 조회되는 데이터를 캐시하여 DB 접근 빈도를 낮춤
- **네트워크 비용 절감**: 원격 서버 요청을 줄여 트래픽 및 지연 시간 개선
- **시스템 확장성 향상**: 부하 분산 및 빠른 데이터 제공을 통해 확장에 용이
- **사용자 경험 개선**: 빠른 응답으로 사용자 만족도 증가

### 1.1.2 캐시의 동작 원리

캐시는 일반적으로 **Key-Value** 형태로 데이터를 저장하며, 아래와 같이 작동합니다.

1. **요청 발생**: 사용자가 데이터를 요청하면 먼저 캐시를 확인
2. **캐시 적중(Cache Hit)**: 캐시에 데이터가 있으면 즉시 반환
3. **캐시 미스(Cache Miss)**: 캐시에 데이터가 없으면 원본 데이터베이스에서 조회 후 캐시에 저장
4. **캐시 만료(Cache Expiration)**: 저장된 데이터는 일정 시간이 지나면 삭제되거나 갱신됨

### 1.1.3 캐시의 주요 유형

1. **CPU 캐시**: CPU 내부의 고속 메모리로, 자주 사용하는 데이터를 저장
2. **메모리 캐시(RAM 캐시)**: 애플리케이션에서 사용하는 주요 데이터를 메모리에 저장하여 빠른 접근 보장
3. **디스크 캐시**: SSD/HDD에 자주 접근하는 데이터를 미리 저장하여 입출력 속도 향상
4. **네트워크 캐시**: CDN 등에서 자주 요청되는 데이터를 저장하여 서버 부하 감소
5. **애플리케이션 캐시**: Redis, Memcached 등 외부 캐시 시스템을 활용해 성능 최적화

### 1.1.3 캐시의 **단점 또는 한계**

1. **데이터 일관성 문제**: 캐시와 데이터베이스 간의 데이터 불일치로 인해 최신 데이터가 아닌 오래된 데이터를 제공할 수 있습니다.
2. **메모리 사용량 증가**: 캐시 데이터가 누적되면 메모리 사용량이 증가하여 시스템 성능에 부정적인 영향을 미칠 수 있습니다.
3. **캐시 관리의 복잡성 증가**: 캐시의 효율적인 운영을 위해서는 무효화, 갱신, 만료 등의 전략을 수립하고 관리해야 하며, 이는 시스템 복잡성을 높입니다.

---

## 1.2 캐시 전략

캐시를 효율적으로 운영하기 위해 다양한 전략이 존재합니다. 아래는 대표적인 **4가지 캐시 전략**과 각 전략이 적합한 상황에 대한 설명입니다.

### 1.2.1 Write-Through

- **개념**: 데이터가 캐시에 저장될 때 동시에 데이터베이스에도 기록되는 방식
- **장점**: 데이터 일관성이 유지되며, 항상 최신 상태를 반영
- **단점**: 모든 쓰기 연산이 DB에도 반영되므로 쓰기 성능에 영향을 줄 수 있음
- **활용 상황**: 데이터 무결성이 매우 중요한 경우

### 1.2.2 Write-Back

- **개념**: 데이터가 먼저 캐시에 기록되고, 일정 주기 또는 특정 조건에 따라 DB에 반영됨
- **장점**: 쓰기 연산의 속도 향상 및 DB 부하 감소
- **단점**: 캐시 장애 시 데이터 손실 위험 및 일시적 데이터 불일치 발생 가능
- **활용 상황**: 쓰기 작업이 빈번하고, 약간의 불일치를 감수할 수 있는 환경

### 1.2.3 Write-Around

- **개념**: 쓰기 작업 시 캐시를 거치지 않고 바로 데이터베이스에 기록함
- **장점**: 캐시 미스 시 DB에서 읽어온 데이터를 캐시하지 않기 때문에 캐시 공간이 절약됨
- **단점**: 동일 데이터가 다시 요청될 때 캐시 미스로 인한 응답 지연 발생 가능
- **활용 상황**: 업데이트 빈도가 낮고, 캐시 공간을 효율적으로 사용하고자 할 때

### 1.2.4 Cache-Aside (Lazy Loading / Read Through)

- **개념**: 애플리케이션이 먼저 캐시에서 데이터를 조회하고, 없으면 DB에서 읽어와 캐시에 저장하는 방식
    - **Read Through** 방식은 캐시 시스템이 자동으로 DB 조회를 연계하는 형태
- **장점**: 필요한 데이터만 캐시에 저장해 메모리 효율을 극대화
- **단점**: 첫 조회 시 캐시 미스가 발생하며, 별도의 캐시 갱신 로직 필요
- **활용 상황**: 읽기 요청이 빈번하지만 데이터 변경은 상대적으로 적은 경우

---

## 1.3 캐시 갱신 전략

캐시 데이터의 일관성을 유지하기 위해 다양한 갱신 전략을 사용할 수 있습니다.

### 1.3.1 TTL(Time-To-Live) 설정

- **개념**: 캐시된 데이터에 만료 시간을 설정하여 일정 시간이 지나면 자동 삭제
- **장점**: 오래된 데이터 유지 방지 및 메모리 관리 용이
- **단점**: 만료 후 데이터 조회 시 캐시 미스로 인한 지연 발생

### 1.3.2 LRU(Least Recently Used)

- **개념**: 가장 오래 사용되지 않은 데이터를 우선적으로 삭제
- **장점**: 최근 자주 사용된 데이터는 캐시에 남아 성능 유지
- **단점**: 특정 사용 패턴에서는 비효율적일 수 있음

### 1.3.3 LFU(Least Frequently Used)

- **개념**: 사용 빈도가 가장 낮은 데이터를 삭제하는 방식
- **장점**: 전체 사용 빈도를 고려하여 캐시 효율성을 높임
- **단점**: 최근에 사용된 데이터를 고려하지 않으므로 상황에 따라 단점 존재

### 1.3.4 Multi-Level Cache(다단계 캐싱)

- **개념**: 여러 단계의 캐시(L1, L2, L3 등)를 두어 데이터 접근 속도를 최적화
- **예시**: CPU 캐시(L1, L2) → 애플리케이션 메모리 캐시 → Redis 같은 외부 캐시 → 데이터베이스
- **장점**: 각 레벨에서 빠른 응답을 제공하며, 부하를 분산

---

## 1.4 캐시 무효화(Invalidation) 전략

1. **수동 무효화(Manual Invalidation)**: 특정 조건에 따라 관리자가 직접 캐시를 삭제.
2. **시간 기반 무효화(Time-based Expiration)**: 일정 시간이 지나면 자동으로 캐시 데이터를 삭제.
3. **Write-through & Write-back 동기화 기반 삭제**: 데이터 변경 시 캐시도 자동으로 갱신되거나 삭제됨.

---

## 1.5 캐시 스탬피드(Cache Stampede) 현상

캐시 스탬피드는 다수의 요청이 동시에 캐시 미스를 유발하여 원본 데이터베이스에 과도한 부하를 주는 현상입니다. 특히 특정 키의 만료 시점에 집중적으로 발생할 수 있습니다.

### 1.5.1 문제점

- 다수의 요청이 동시에 DB 조회를 실행하여 DB 부하 급증
- 성능 저하 및 응답 지연 발생

### 1.5.2 해결 방안

- **Mutex Lock (Lazy Loading + Locking)**: 특정 키에 대해 하나의 요청만 DB 조회를 허용하고, 나머지는 대기시킴
- **Early Expiration**: 만료 전에 미리 데이터를 갱신하여 캐시 미스 폭주 방지
- **Random Expiration**: 캐시 키의 만료 시간을 무작위로 설정하여 동시에 만료되는 현상 방지
- **Multi-Level Cache**: 다단계 캐시로 부하를 분산하여 단일 캐시 미스로 인한 DB 조회 감소

---

## 1.6 캐시 히트율

- **캐시 히트율(Cache Hit Rate)**: 캐시 시스템에서 데이터가 성공적으로 반환된 비율을 의미합니다. 높은 캐시 히트율은 시스템 성능 향상에 기여하며, DB에 대한 불필요한 접근을 줄여줍니다.
    - **계산 방법**: $캐시히트율 = \frac{캐시히트회수}{캐시히트회수 + 캐시미스회수}$
    - 높은 캐시 히트율을 달성하려면 **효율적인 캐시 갱신** 전략과 **적절한 TTL(Time-to-Live)** 설정이 중요합니다.

---

# 2. e‑커머스 시스템 설계 보고서

아래는 기존 e‑커머스 주문 및 결제 시스템 설계를 바탕으로 Redis를 활용한 캐싱 및 대기열 적용 방안을 포함한 사례입니다.

## 2.1 기존 시스템 개요

### 2.1.1 주문 및 결제

- **결제 방식**: 잔액 기반 결제
- **주문 이력**: 주문 성공/실패 이력 저장

### 2.1.2 상품 판매량 통계

- **테이블 구성**: `ProductDailySales` 테이블 활용
- **업데이트**: 주문 성공 시 상품 판매량 업데이트

### 2.1.3 선착순 쿠폰 발급

- 선착순으로 한정된 쿠폰을 중복되지 않게 발급

---

## 2.2 Redis 적용 방안

### 2.2.1 상위 상품 조회 캐싱

### ✅ 목표

- 최근 3일간 판매량을 기준으로 상위 상품을 조회하여 빠른 응답 제공 및 DB 부하 감소

### ✅ 구현 방식

1. **배치 스케줄링**: 매일 새벽 0시에 실행
2. **데이터 집계**: `ProductDailySales` 테이블에서 최근 3일간 판매량 집계
3. **Redis 캐싱 활용** : 상품 ID와 판매량(score)을 저장하여 정렬된 상위 목록 생성
4. **TTL 설정**: 24시간 후 자동 만료

```java
// 주기적으로 캐시 갱신
    @Scheduled(cron = "0 0 0 * * ?") // 매일 자정에 실행
    public void refreshCache() {
        LocalDate today = LocalDate.now();
        LocalDate threeDaysAgo = today.minusDays(3);
        List<ProductDailySales> salesData = productDailySalesRepository.findTopSellingProductsForPeriod(threeDaysAgo, today, PageRequest.of(0, 5));
        redisTemplate.opsForValue().set(CACHE_KEY, salesData, 1, TimeUnit.DAYS); // 캐시 만료 시간 설정
    }

```

## **ZSET을 사용하는 게 Key-Value보다 더 유리할까?**

### ✅ 1. **쿼리 부담 감소 (DB 부하 줄이기)**

- 현재 쿼리는 `ORDER BY p.dailyQuantitySold DESC`를 사용하여 **매번 정렬 연산이 수행됨**
- DB에서 정렬하는 작업은 **데이터가 많아질수록 부담이 커짐** (특히 인덱스가 없거나 범위가 넓을 때)
- ZSET을 활용하면, **이미 정렬된 데이터를 Redis에서 O(logN)으로 가져올 수 있어** **DB 부하를 줄일 수 있음**

### ✅ 2. **빠른 조회**

- DB를 직접 조회하면 최소한 **네트워크 요청 + DB 쿼리 실행 + 정렬 비용**이 발생
- 반면, Redis ZSET의 `ZREVRANGE`는 **O(logN)으로 즉시 정렬된 데이터 제공**
- 즉, **DB 조회 없이** `ZREVRANGE`로 바로 가져올 수 있어서 **조회 속도가 빨라짐**

### ✅ 3. **부분 업데이트 가능**

- 특정 상품의 판매량이 바뀌었을 때 **부분 업데이트**가 가능
    - 예를 들어, 새로운 판매 기록이 추가되면 `ZADD`로 해당 상품의 판매량만 갱신하면 됨
- 반면, Key-Value 방식은 **전체 데이터 갱신이 필요** (덮어쓰기 방식)

---

## **2️⃣ 일반 Key-Value 방식보다 ZSET이 적합한 이유**

| 비교 항목 | ZSET 활용 | 일반 Key-Value |
| --- | --- | --- |
| **정렬된 조회 속도** | ✅ 빠름 (O(logN)) | ❌ 느림 (리스트 정렬 필요) |
| **DB 부하 감소** | ✅ DB 접근 없음 | ❌ 매번 DB 조회 필요 |
| **부분 업데이트** | ✅ 가능 (`ZADD`) | ❌ 불가능 (전체 덮어쓰기 필요) |
| **구현 난이도** | ⚠️ 상대적으로 복잡 | ✅ 간단 |

---

## **3️⃣ 결론**

### **➡️ ZSET이 더 적합한 경우**

- **조회 성능 최적화**가 필요할 때
- **DB 부하를 줄이고 싶을 때** (특히 트래픽이 많을 경우)
- **부분 업데이트**가 필요할 때

### **➡️ 일반 Key-Value가 더 적합한 경우**

- **배치 실행으로 정해진 시점에만 데이터 갱신**하는 경우
- **정렬된 조회가 필요 없는 경우**
- **구현을 최대한 단순하게 유지하고 싶을 때**

**👉 따라서, 판매량 통계가 실시간이 아니기에 key-value가 훨씬 더 적합함!** 🚀

---

### 2.2.2 선착순 쿠폰 대기열 적용

### ✅ 목표

- 빠른 응답과 공정한 선착순 쿠폰 발급을 위해 대기열을 적용

### ✅ 구현 방식

### **(1) 사용자 요청 추가 (선착순 큐 등록)**

```java

public boolean requestCoupon(Long userId) {
    Long queueSize = redisTemplate.opsForZSet().zCard("coupon_queue");
    if (queueSize != null && queueSize >= MAX_COUPONS) return false;

    double timestamp = (double) System.currentTimeMillis(); // 요청 시간 기반 우선순위
    redisTemplate.opsForZSet().add("coupon_queue", userId.toString(), timestamp);
    return true;
}

```

### **(2) 대기열에서 사용자 처리 (선착순 쿠폰 발급)**

```java

@Scheduled(fixedDelay = 1000)
public void processCouponQueue() {
    Set<String> users = redisTemplate.opsForZSet().range("coupon_queue", 0, 0); // 첫 번째 사용자 조회
    if (users != null && !users.isEmpty()) {
        String userId = users.iterator().next();
        if (redisTemplate.opsForZSet().remove("coupon_queue", userId) > 0) {
            couponService.issueCoupon(Long.parseLong(userId));
        }
    }
}

```

### **(3) 5분 이상 지난 요청 자동 삭제**

```java

public void cleanUpOldRequests() {
    long expirationTime = System.currentTimeMillis() - (5 * 60 * 1000); // 5분 전 기준
    redisTemplate.opsForZSet().removeRangeByScore("coupon_queue", 0, expirationTime);
}

```

## **ZSET을 사용하는 게 Redis List보다 더 유리할까?**

## **1️⃣ Redis List 방식인 경우에 발생할수 는 문제점**

`LPUSH` + `RPOP`으로 대기열을 관리하는 방식으로 진행하는 경우.

### ❌ **1. 선착순이 완벽히 보장되지 않음**

- `LPUSH`는 **왼쪽에 삽입**하고 `RPOP`은 **오른쪽에서 제거**하는 구조인데,> **동시 요청이 많을 때, 삽입 순서가 꼬일 가능성**이 있음
- 예를 들어, 여러 개의 `LPUSH`가 동시에 들어오면, 요청이 밀려도 먼저 들어온 사람이 뒤로 밀릴 수도 있음

### ❌ **2. 요청이 너무 많을 경우 큐 관리가 어려움**

- 단순한 List(`LPUSH`, `RPOP`) 방식에서는 **대기 순서 외에 추가적인 정보(타임스탬프, 우선순위 등)를 반영하기 어려움**
- 특정 사용자를 큐에서 **빠르게 조회하거나 취소하는 기능이 어려움**
- TTL 적용이 어려움 (List 내 개별 요소에 TTL을 걸 수 없음)

---

## **2️⃣ ZSET을 활용하는 경우 생기는 장점**

### ✅ **1. 정확한 선착순 유지 (`score` = 요청 시간)**

- `ZADD("coupon_queue", timestamp, userId)` 사용
- `ZRANGE` 또는 `ZRANK`로 정확한 선착순 유지 가능
- `ZPOPMIN("coupon_queue")`으로 **가장 오래된 요청을 정확히 꺼낼 수 있음** (즉, **선착순 보장!**)

### ✅ **2. 빠른 조회 및 특정 사용자 처리 가능**

- 특정 사용자가 대기열에서 몇 번째인지 **빠르게 조회 가능 (`ZRANK`)**
- 특정 사용자의 대기열 취소도 가능 (`ZREM`)

### ✅ **3. TTL 적용 가능**

- TTL을 직접 적용하지 못하더라도, `timestamp` 기준으로 자동 삭제 가능
    - 예: `ZREMRANGEBYSCORE("coupon_queue", 0, old_timestamp)`를 사용해서 **5분 이상 지난 요청 삭제 가능**

---

## **3️⃣ 결론: ZSET이 더 나은 이유**

| 비교 항목 | 기존 List 방식 (`LPUSH` + `RPOP`) | ZSET 방식 (`ZADD` + `ZPOPMIN`) |
| --- | --- | --- |
| **선착순 보장** | ❌ 동시 요청 시 순서 꼬일 가능성 | ✅ 정확한 순서 보장 |
| **빠른 조회** | ❌ 순차적으로 검색해야 함 | ✅ `ZRANK`로 O(logN) 조회 |
| **개별 취소 가능 여부** | ❌ 불가능 | ✅ `ZREM(userId)` 사용 가능 |
| **TTL 적용 가능 여부** | ❌ 어려움 | ✅ `ZREMRANGEBYSCORE` 활용 가능 |

**👉 따라서, 선착순 보장이 중요한 쿠폰 대기열에서는 ZSET이 훨씬 더 적합함!** 🚀

---

# 3. 종합 결론

캐시는 **시스템 응답 속도 향상**, **DB 부하 경감**, **네트워크 비용 절감** 등 여러 측면에서 중요한 역할을 합니다.

캐시 전략을 선택할 때, `Write-Through`와 `Cache-Aside` 전략을 적절히 활용하여 캐시 효율을 극대화하고, 자주 조회되는 데이터는 캐시에서 바로 반환하도록 합니다. 이로써 캐시 히트율을 높일 수 있습니다.

- **Write-Through**: 데이터 일관성이 최우선인 경우
- **Write-Back**: 쓰기 부하가 많을 때
- **Write-Around**: 불필요한 데이터 캐싱 방지 필요 시
- **Cache-Aside (Read Through)**: 읽기 요청이 빈번한 환경에 적합합니다.

특히 e‑커머스 시스템에서는 **상위 상품 조회 캐싱**과 **선착순 쿠폰 대기열**을 적용함으로써

빠른 응답과 공정한 서비스 제공, 그리고 안정적인 시스템 운영을 동시에 달성할 수 있습니다.

향후에는 실시간 모니터링, 부하 테스트, 그리고 캐시 전략의 최적화를 통해 보다 발전된 시스템을 구축할 수 있도록 해야 합니다.
